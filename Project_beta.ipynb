{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import numpy as np\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pulling the data from the twitter\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets100000.txt\", \"w\")\n",
    "\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write( json.dumps(tweet) + '\\n' )\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100000:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "\n",
    "TWITTER_APP_KEY = \"Pf6yHj89pVFEc7Mhggjb85nlg\"\n",
    "TWITTER_APP_SECRET = \"E3vxWMVKBmlHIRYxBRZilnTnqEhFZEVET1INxtY7DNT2hUnS9o\"\n",
    "TWITTER_KEY = \"718262361560363010-CYtqTAzViWwtxohgCZYpTEuxTxs9Git\"\n",
    "TWITTER_SECRET = \"XjglyjoiFfna1CwBEuoXbc9LquJSFgOrwmCa26RDdf9wA\"\n",
    "auth = tweepy.OAuthHandler(TWITTER_APP_KEY, TWITTER_APP_SECRET)\n",
    "auth.set_access_token(TWITTER_KEY, TWITTER_SECRET)\n",
    "\n",
    "listen_happy = MyStreamListener()\n",
    "stream = tweepy.Stream(auth,listen_happy)\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "#stream.filter(track = [\"Happiness\",\"Good\",\"nice\",\"Happy\",\"joy\",\"joyful\",\"smile\",\"Happy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'contributors', u'truncated', u'text', u'is_quote_status', u'in_reply_to_status_id', u'id', u'favorite_count', u'source', u'retweeted', u'coordinates', u'timestamp_ms', u'entities', u'in_reply_to_screen_name', u'in_reply_to_user_id', u'retweet_count', u'id_str', u'favorited', u'user', u'geo', u'in_reply_to_user_id_str', u'possibly_sensitive', u'lang', u'created_at', u'filter_level', u'in_reply_to_status_id_str', u'place']\n"
     ]
    }
   ],
   "source": [
    "#Loading the tweets.txt which is saved in earlier code\n",
    "tweets_data = open(\"./tweets100000.txt\",\"r\")\n",
    "tweets = []\n",
    "tweets_number = 0\n",
    "no_of_tweets = 100000\n",
    "for line in tweets_data:\n",
    "    #print(line)\n",
    "    tweets_sample = json.loads(line)\n",
    "    tweets.append(tweets_sample)\n",
    "    tweets_number += 1\n",
    "    if(tweets_number == (no_of_tweets - 10)):\n",
    "        break\n",
    "tweets_data.close()\n",
    "print(tweets[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7fa947c336cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#Creating a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lang\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"location\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1995\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1997\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1999\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2002\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2003\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2004\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\core\\internals.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   3288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3290\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3291\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\pandas\\indexes\\base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   1945\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1947\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4154)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas\\index.c:4018)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12368)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas\\hashtable.c:12322)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "print(tweets[0])\n",
    "#Creating a dataframe\n",
    "tweets = pd.DataFrame(tweets,columns = [\"text\",\"lang\",\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting histogram\n",
      "updating ylabel\n",
      "plotting\n"
     ]
    }
   ],
   "source": [
    "#Analyzing the tweets\n",
    "def word_in_text(word, tweet):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, tweet)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Initialize list to store tweet counts\n",
    "[Food,Chatting,Sleep,Play,Birthday,Football,Money,Eat,Party] = [0, 0, 0, 0,0,0,0,0,0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in tweets.iterrows():\n",
    "    if(index == 100000):\n",
    "        print(index)\n",
    "        break\n",
    "    if(row[\"lang\"] == \"en\"):\n",
    "            Food += word_in_text('Food', row['text'])\n",
    "            Chatting += word_in_text(\"Chatting\", row[\"text\"])\n",
    "            Sleep += word_in_text(\"Sleep\", row[\"text\"])\n",
    "            Play += word_in_text(\"Play\", row[\"text\"])\n",
    "            Birthday += word_in_text(\"Birthday\", row[\"text\"])\n",
    "            Football += word_in_text(\"Football\", row[\"text\"])\n",
    "            Money += word_in_text(\"Money\", row[\"text\"])\n",
    "            Eat += word_in_text(\"Eat\", row[\"text\"])\n",
    "            Party += word_in_text(\"Party\", row[\"text\"])\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['Food', 'Chatting', 'Sleep', 'Play',\"Birthday\",\"Football\",\"Money\",\"Eat\",\"Party\"]\n",
    "\n",
    "# Plot histogram\n",
    "print(\"plotting histogram\")\n",
    "ax = sns.barplot(cd, [Food,Chatting,Sleep,Play,Birthday,Football,Money,Eat,Party])\n",
    "print(\"updating ylabel\")\n",
    "ax.set(ylabel=\"count\")\n",
    "print(\"plotting\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://t.co/601lVIdvT4 So Good @louisa ‚ô•‚ô•</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@norminahoes is saved like 10‚Ç¨ and i bet that ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @Harry_Styles: @oasisxstyles no problem, ha...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @andrewbelle: It feels so good to release n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Podolski10: \"Happy St. Totteringham‚Äôs Day,...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @PinkArg: üì∑ pinksource: Happy Halloween! L...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @irnmortals: im not saying red kryptonite w...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@Harry_Styles and @Louis_Tomlinson you've the ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @SonjaD777: Wow all the love :) yep.. I sti...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RT @CUTEST_ANlMALS: THIS MAKES ME SO HAPPY htt...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Projeto5HFHelp: @WeLuvAllyB Hi Mama and Pa...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Yes babes you tell em. You're a great ass mom ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@damianekf idk if this is you being nice or not</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What's wrong with you dude https://t.co/ttuaaB...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @afshin6666: With trainees in getting ready...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How to believe that you are a good person when...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A good way to send this week behind me on its ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pure quality from the boys today getting 5 poi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT @Jonathan_275: So we're gonna act like ther...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@lectersinom „Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô\\n‰ªäÊó•„ÇÇ‰∏ÄÊó•„Åå„Çì„Å∞„Çä„Åæ„Åó„Çá„ÅÜ  https:/...</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@shun1sta „Åê„Å£„Å©„ÇÇ„Éº„Å´„Çì„Åê ‰ªäÊó•„ÇÇ‰∏ÄÊó•„Åå„Çì„Å∞„Çä„Åæ„Åó„Çá„ÅÜ  https://t.co...</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @FlashtheShihTzu: Happy Halloween, Friends!...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New on #Steemit: Have a Happy Halloween says t...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>#siego xd https://t.co/jCi7ohR842</td>\n",
       "      <td>und</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@RMNOZSN  \\nGood morning</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @kira07921817: ÔºëÊó•Êó©„ÇÅ„ÅÆ„ÅäÊØç„Åï„Çì„ÅÆË™ïÁîüÊó•‰ºöüéâ\\nHappy Birt...</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT @AtlantaFalcons: Nice adjustment by the def...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RT @FemaleTexts: THIS MADE ME SO HAPPY https:/...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RT @IvaStylesVettel: Was one of the most frust...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@cody7snow they let me go, I had some good gui...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>Eminem ft dido _ stan https://t.co/Xdvzhmiqo2</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>RT @AtlantaFalcons: Nice adjustment by the def...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>@kaori55camellia „Åã„Åä„Çä„Å°„ÇÉ„Çì.*ÔΩ•‚ô•ÔæüHappy Birthday ‚ô¨ ¬∞...</td>\n",
       "      <td>ja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>im so weird, i was literally crying my heart o...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>@samagon1269 very nice</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>RT @LesbianTexts: girls are so soft and cuddly...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>Love a good long soak üõÄüèº</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>Walking into the library in my costume with sh...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Nice night to ride around the city</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>RT @kamoo89g: I'm over a lot a shit and it fee...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>RT @jules3romeo: Happy birthday @DylanCurcio2 ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>RT @KardashianHumor: When bae is looking good ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>Diusorrrr thank you so much üíù https://t.co/pm...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>RT @witch_dunk: I wish I could return to my ho...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>Congrats for your french speach in @CW_TheFlas...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>RT @JaDineArmy: Happy birthday, Baby Charriol ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>I'm content with being a good girl with high s...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>@wakamolez tHIS PLACE LOOKS SO GOOD THOUGH, IM...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>RT @supectrum: magnus throws the best partiesÌ†º...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>@mikela_howard bc it's good ??</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>RT @pineaIs: yea compliments on appearance r n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>RT @Ochentaz: 2017 be good to me</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>RT @engrossingfacts: Our brains have a negativ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>RT @F1: ROS: \"It's been a good day. Lewis has ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Steam sale has some good games on their list.\\...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>RT @paythebabe: harvest rocked my socksü§òüèΩand...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>RT @projectgeteven: #SaturdayChallenge ‚òÄÔ∏è‚ú®\\n\\n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>@RPomplun Hello Raquel happy birthday may ALL ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>RT @marienassar_: @AlinaDal_F  Happy evening d...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>RT @shawnmendestuff: let's win this for him to...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text lang\n",
       "0           https://t.co/601lVIdvT4 So Good @louisa ‚ô•‚ô•   en\n",
       "1    @norminahoes is saved like 10‚Ç¨ and i bet that ...   en\n",
       "2    RT @Harry_Styles: @oasisxstyles no problem, ha...   en\n",
       "3    RT @andrewbelle: It feels so good to release n...   en\n",
       "4    RT @Podolski10: \"Happy St. Totteringham‚Äôs Day,...   en\n",
       "5    RT @PinkArg: üì∑ pinksource: Happy Halloween! L...   en\n",
       "6    RT @irnmortals: im not saying red kryptonite w...   en\n",
       "7    @Harry_Styles and @Louis_Tomlinson you've the ...   en\n",
       "8    RT @SonjaD777: Wow all the love :) yep.. I sti...   en\n",
       "9    RT @CUTEST_ANlMALS: THIS MAKES ME SO HAPPY htt...   en\n",
       "10   RT @Projeto5HFHelp: @WeLuvAllyB Hi Mama and Pa...   en\n",
       "11   Yes babes you tell em. You're a great ass mom ...   en\n",
       "12     @damianekf idk if this is you being nice or not   en\n",
       "13   What's wrong with you dude https://t.co/ttuaaB...   en\n",
       "14   RT @afshin6666: With trainees in getting ready...   en\n",
       "15   How to believe that you are a good person when...   en\n",
       "16   A good way to send this week behind me on its ...   en\n",
       "17   Pure quality from the boys today getting 5 poi...   en\n",
       "18   RT @Jonathan_275: So we're gonna act like ther...   en\n",
       "19   @lectersinom „Åä„ÅØ„Çà„ÅÜ„Åî„Åñ„ÅÑ„Åæ„Åô\\n‰ªäÊó•„ÇÇ‰∏ÄÊó•„Åå„Çì„Å∞„Çä„Åæ„Åó„Çá„ÅÜ  https:/...   ja\n",
       "20   @shun1sta „Åê„Å£„Å©„ÇÇ„Éº„Å´„Çì„Åê ‰ªäÊó•„ÇÇ‰∏ÄÊó•„Åå„Çì„Å∞„Çä„Åæ„Åó„Çá„ÅÜ  https://t.co...   ja\n",
       "21   RT @FlashtheShihTzu: Happy Halloween, Friends!...   en\n",
       "22   New on #Steemit: Have a Happy Halloween says t...   en\n",
       "23                   #siego xd https://t.co/jCi7ohR842  und\n",
       "24                            @RMNOZSN  \\nGood morning   en\n",
       "25   RT @kira07921817: ÔºëÊó•Êó©„ÇÅ„ÅÆ„ÅäÊØç„Åï„Çì„ÅÆË™ïÁîüÊó•‰ºöüéâ\\nHappy Birt...   ja\n",
       "26   RT @AtlantaFalcons: Nice adjustment by the def...   en\n",
       "27   RT @FemaleTexts: THIS MADE ME SO HAPPY https:/...   en\n",
       "28   RT @IvaStylesVettel: Was one of the most frust...   en\n",
       "29   @cody7snow they let me go, I had some good gui...   en\n",
       "..                                                 ...  ...\n",
       "969      Eminem ft dido _ stan https://t.co/Xdvzhmiqo2   en\n",
       "970  RT @AtlantaFalcons: Nice adjustment by the def...   en\n",
       "971  @kaori55camellia „Åã„Åä„Çä„Å°„ÇÉ„Çì.*ÔΩ•‚ô•ÔæüHappy Birthday ‚ô¨ ¬∞...   ja\n",
       "972  im so weird, i was literally crying my heart o...   en\n",
       "973                             @samagon1269 very nice   en\n",
       "974  RT @LesbianTexts: girls are so soft and cuddly...   en\n",
       "975                         Love a good long soak üõÄüèº   en\n",
       "976  Walking into the library in my costume with sh...   en\n",
       "977                 Nice night to ride around the city   en\n",
       "978  RT @kamoo89g: I'm over a lot a shit and it fee...   en\n",
       "979  RT @jules3romeo: Happy birthday @DylanCurcio2 ...   en\n",
       "980  RT @KardashianHumor: When bae is looking good ...   en\n",
       "981  Diusorrrr thank you so much üíù https://t.co/pm...   en\n",
       "982  RT @witch_dunk: I wish I could return to my ho...   en\n",
       "983  Congrats for your french speach in @CW_TheFlas...   en\n",
       "984  RT @JaDineArmy: Happy birthday, Baby Charriol ...   en\n",
       "985  I'm content with being a good girl with high s...   en\n",
       "986  @wakamolez tHIS PLACE LOOKS SO GOOD THOUGH, IM...   en\n",
       "987  RT @supectrum: magnus throws the best partiesÌ†º...   en\n",
       "988                     @mikela_howard bc it's good ??   en\n",
       "989  RT @pineaIs: yea compliments on appearance r n...   en\n",
       "990                   RT @Ochentaz: 2017 be good to me   en\n",
       "991  RT @engrossingfacts: Our brains have a negativ...   en\n",
       "992  RT @F1: ROS: \"It's been a good day. Lewis has ...   en\n",
       "993  Steam sale has some good games on their list.\\...   en\n",
       "994  RT @paythebabe: harvest rocked my socksü§òüèΩand...   en\n",
       "995  RT @projectgeteven: #SaturdayChallenge ‚òÄÔ∏è‚ú®\\n\\n...   en\n",
       "996  @RPomplun Hello Raquel happy birthday may ALL ...   en\n",
       "997  RT @marienassar_: @AlinaDal_F  Happy evening d...   en\n",
       "998  RT @shawnmendestuff: let's win this for him to...   en\n",
       "\n",
       "[999 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotting histogram\n",
      "updating ylabel\n",
      "plotting\n"
     ]
    }
   ],
   "source": [
    "#Analyzing the tweets\n",
    "def word_in_text(word, tweet):\n",
    "    word = word.lower()\n",
    "    text = tweet.lower()\n",
    "    match = re.search(word, tweet)\n",
    "\n",
    "    if match:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Initialize list to store tweet counts\n",
    "[games,health,love,nature] = [0, 0, 0, 0]\n",
    "\n",
    "# Iterate through df, counting the number of tweets in which\n",
    "# each candidate is mentioned\n",
    "for index, row in tweets.iterrows():\n",
    "    if(index == 100000):\n",
    "        print(index)\n",
    "        break\n",
    "    if(row[\"lang\"] == \"en\"):\n",
    "            games += word_in_text('games', row['text'])\n",
    "            health += word_in_text(\"health\", row[\"text\"])\n",
    "            love += word_in_text(\"love\", row[\"text\"])\n",
    "            nature += word_in_text(\"nature\", row[\"text\"])\n",
    "            \n",
    "# Set seaborn style\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "# Create a list of labels:cd\n",
    "cd = ['games', 'health', 'love', 'nature']\n",
    "\n",
    "# Plot histogram\n",
    "print(\"plotting histogram\")\n",
    "ax = sns.barplot(cd, [games,health,love,nature])\n",
    "print(\"updating ylabel\")\n",
    "ax.set(ylabel=\"count\")\n",
    "print(\"plotting\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
